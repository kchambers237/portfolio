{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fc8f1b",
   "metadata": {},
   "source": [
    "\n",
    "PROJECT AIM \n",
    "-----------\n",
    "Construct an Hourly Price Forward Curve (HPFC) for electricity markets that:\n",
    "\n",
    "1. Preserves the observed weekly base price (market consistency)\n",
    "2. Captures realistic intraday price patterns (peak / off-peak)\n",
    "3. Incorporates solar production effects \n",
    "4. Is stable, interpretable, and suitable for production deployment\n",
    "\n",
    "MODELING STRATEGY approach:\n",
    "\n",
    "STAGE 1 - SHAPE LEARNING\n",
    "* Normalize prices by weekly mean\n",
    "* Learn pure intraday shapes\n",
    "* Estimate solar impact on price shape \n",
    "\n",
    "STAGE 2 - SCALING\n",
    "* Reintroduce weekly price level\n",
    "* Apply weekly scaling\n",
    "* Ensure weekly mean consistency by construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f95361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5351298",
   "metadata": {},
   "source": [
    "# Data Access Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3159145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def load_spot_prices(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        replace missing prices with average weekly prices\n",
    "        \"\"\"\n",
    "        df = pd.read_excel('hpfc.xlsx')\n",
    "        df.columns  = df.columns.str.lower()\n",
    "        df = df.rename(columns={\"datum\": \"timestamp\", \"preis\": \"price\"})\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.set_index('timestamp').sort_index()\n",
    "        full_idx = pd.date_range(start=df.index.min(),\n",
    "                                end=df.index.max(),\n",
    "                                freq='h')\n",
    "        df = df.reindex(full_idx)\n",
    "        weekly_mean = df['price'].groupby(df.index.to_period('W')).transform('mean')\n",
    "        df['price'] = df['price'].fillna(weekly_mean)\n",
    "        df = df.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "        return df\n",
    "    \n",
    "    def load_solar(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Synthesize solar data ---\n",
    "        \"\"\"\n",
    "        rng = pd.date_range(start = \"2019-01-01\", end = \"2023-12-31\", freq=\"h\")\n",
    "        solar = np.clip(np.sin(2 * np.pi * (rng.hour - 6) / 24), 0, 1)   \n",
    "        df = pd.DataFrame({\"timestamp\": rng, \"solar\": solar}) \n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815f80d",
   "metadata": {},
   "source": [
    "Time and Market Structure Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece24a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_bucket(month: int) -> str:\n",
    "    \"\"\"\n",
    "    Maps months into market-relevant seasonal buckets.\n",
    "    \"\"\"\n",
    "    if month in [5, 6, 7, 8]:\n",
    "        return \"summer\"\n",
    "    if month in [11, 12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    if month in [10, 3]:\n",
    "        return \"winter_transition\"\n",
    "    return \"summer_transition\"\n",
    "\n",
    "\n",
    "def is_peak(ts: pd.Timestamp) -> bool:\n",
    "    \"\"\"\n",
    "    Defines peak hours:\n",
    "    * Monday - Friday\n",
    "    * 08:00 - 20:00\n",
    "    \"\"\"\n",
    "    return ts.weekday() < 5 and 8 <= ts.hour <= 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721cd01",
   "metadata": {},
   "source": [
    "Shape Model Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75384fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ShapeModel:\n",
    "    \"\"\"\n",
    "    Stores learned intraday structures.\n",
    "    \"\"\"\n",
    "    x: np.ndarray       # Peak-hour shape (24)\n",
    "    y: np.ndarray       # Off-peak shape (24)\n",
    "    beta: dict          # Solar sensitivity per seasonal bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b4dbcc",
   "metadata": {},
   "source": [
    "# Shape Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f1550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapePredictor:\n",
    "    \"\"\"\n",
    "    SHAPE LEARNING\n",
    "    \n",
    "    Learns:\n",
    "    * Peak shape x_k\n",
    "    * Off-peak shape y_k\n",
    "    * Solar depression effect beta_b\n",
    "    \n",
    "    All predictions are done on WEEKLY-NORMALIZED prices\n",
    "    to remove absolute price levels.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, df: pd.DataFrame) -> ShapeModel:\n",
    "        df = df.copy()\n",
    "        \n",
    "        #   --- Time features ---\n",
    "        df['week'] = df['timestamp'].dt.isocalendar().week\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['bucket'] = df['timestamp'].dt.month.map(seasonal_bucket)\n",
    "        \n",
    "        # --- Weekly normalization ---\n",
    "        df[\"weekly_mean\"] = df.groupby(\"week\")['price'].transform('mean')\n",
    "        df['s_norm'] = df[\"price\"] / df[\"weekly_mean\"]\n",
    "        \n",
    "        # --- Initialize shapes ---\n",
    "        x = np.zeros(24)\n",
    "        y = np.zeros(24)\n",
    "        \n",
    "        # --- Predict average normalized price per hour ---\n",
    "        for h in range(24):\n",
    "            peak_mask = (df['hour'] == h) & df['timestamp'].apply(is_peak)\n",
    "            off_mask = (df['hour'] == h) & ~df['timestamp'].apply(is_peak)\n",
    "            \n",
    "            if peak_mask.any():\n",
    "                x[h] = df.loc[peak_mask, \"s_norm\"].mean()\n",
    "            if off_mask.any():\n",
    "                y[h] = df.loc[off_mask, \"s_norm\"].mean()\n",
    "\n",
    "        # --- Enforce market structure ---\n",
    "        for h in range(24):\n",
    "            if not (8 <= h <= 20):\n",
    "                x[h] = 0\n",
    "            if 8 <= h <= 20:\n",
    "                y[h] = 0\n",
    "                \n",
    "        # --- Normalize shapes ---\n",
    "        x /= x.sum()\n",
    "        y /= y.sum()\n",
    "        \n",
    "        # --- Solar sensitivity prediction ---\n",
    "        beta = {}\n",
    "        for b in df[\"bucket\"].unique():\n",
    "            sub = df[df[\"bucket\"] == b]\n",
    "            if len(sub) > 20:\n",
    "                # Solar lowers prices => positive beta \n",
    "                beta[b] = max(0, np.cov(sub[\"solar\"], sub[\"s_norm\"])[0, 1])\n",
    "            else:\n",
    "                beta[b] = 0.0\n",
    "        \n",
    "        return ShapeModel(x=x, y=y, beta=beta)          \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a942ac",
   "metadata": {},
   "source": [
    "# HPFC Construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b9951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPFCModel:\n",
    "    \"\"\"\n",
    "    PRICE LEVEL REINTRODUCTION\n",
    "    \n",
    "    Apply Weekly Scaling:\n",
    "    * Preserves weekly mean exactly\n",
    "    * Apply learned shapes and solar correction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, shape_model: ShapeModel):\n",
    "        self.shape = shape_model\n",
    "        \n",
    "    def forecast(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        \n",
    "        df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "        df[\"week\"] = df[\"timestamp\"].dt.isocalendar().week\n",
    "        df[\"bucket\"] = df[\"timestamp\"].dt.month.map(seasonal_bucket)\n",
    "        \n",
    "        # --- Weekly statistics ---\n",
    "        df[\"weekly_mean\"] = df.groupby ('week')[\"price\"].transform(\"mean\")\n",
    "        \n",
    "        peak_mean = df[df[\"timestamp\"].apply(is_peak)].groupby('week')['price'].mean()\n",
    "        off_mean = df[~df['timestamp'].apply(is_peak)].groupby('week')['price'].mean()\n",
    "        \n",
    "        df['peak_mean'] = df['week'].map(peak_mean)\n",
    "        df['offpeak_mean'] = df['week'].map(off_mean)\n",
    "        \n",
    "        # --- Raw hourly forecast ---\n",
    "        def raw_price(row):\n",
    "            h = row['hour']\n",
    "            price = (\n",
    "                row[\"peak_mean\"] * self.shape.x[h]\n",
    "                + row['offpeak_mean'] * self.shape.y[h]\n",
    "            )\n",
    "            price -= (\n",
    "                row['weekly_mean'] * self.shape.beta.get(row['bucket'], 0)\n",
    "            )\n",
    "            return price\n",
    "        \n",
    "        df['raw_forecast'] = df.apply(raw_price, axis=1)\n",
    "        \n",
    "        # --- Weekly scaling ---\n",
    "        df[\"raw_week_mean\"] = df.groupby('week')[\"raw_forecast\"].transform('mean')\n",
    "        df['hpfc'] = df['weekly_mean'] * df['raw_forecast'] / df['raw_week_mean']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc705edb",
   "metadata": {},
   "source": [
    "# Metrics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437cdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPFCPlots:\n",
    "    def __init__(self, df, dt_col='timestamp'):\n",
    "        self.df = df.copy()\n",
    "        self.df[dt_col] = pd.to_datetime(self.df[dt_col])\n",
    "        self.df = self.df.set_index(dt_col).sort_index()\n",
    "\n",
    "    def _layout(self, title):\n",
    "        return dict(\n",
    "            title=title,\n",
    "            hovermode='x unified',\n",
    "            xaxis=dict(\n",
    "                tickformat='%a %H:%M',\n",
    "                dtick=4 * 60 * 60 * 1000,  # 4 hours\n",
    "                showgrid=True\n",
    "            ),\n",
    "            yaxis=dict(title='Price'),\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "\n",
    "    def plot_hpfc_vs_observed(self):\n",
    "        df = self.df.copy()\n",
    "        # extract weekday & hour\n",
    "        df['weekday'] = df.index.weekday   # Mon=0\n",
    "        df['hour'] = df.index.hour\n",
    "\n",
    "        # group by weekday + hour\n",
    "        agg = (\n",
    "            df\n",
    "            .groupby(['weekday', 'hour'])[['price', 'hpfc']]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # ordering key: Mon 00 â†’ Sun 23\n",
    "        agg['week_pos'] = agg['weekday'] * 24 + agg['hour']\n",
    "        agg = agg.sort_values('week_pos')\n",
    "        \n",
    "        # synthetic x-axis only for labeling\n",
    "        week_start = pd.Timestamp('2025-01-06')  # Monday\n",
    "        agg['x'] = (\n",
    "            week_start\n",
    "            + pd.to_timedelta(agg['weekday'], unit='D')\n",
    "            + pd.to_timedelta(agg['hour'], unit='H')\n",
    "        )\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=agg['x'],\n",
    "            y=agg['price'],\n",
    "            name='price',\n",
    "            mode='lines'\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=agg['x'],\n",
    "            y=agg['hpfc'],\n",
    "            name='HPFC',\n",
    "            mode='lines'\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title='HPFC vs Observed Prices',\n",
    "            hovermode='x unified',\n",
    "            xaxis=dict(\n",
    "                tickformat='%a %H:%M',\n",
    "                dtick=4 * 60 * 60 * 1000,\n",
    "                showgrid=True\n",
    "            ),\n",
    "            yaxis=dict(title='Price'),\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97239f5f",
   "metadata": {},
   "source": [
    "# End-to-End Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a608ab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChamberlinKeuleck\\AppData\\Local\\Temp\\ipykernel_24912\\4172175086.py:43: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Load data ---\n",
    "loader = DataLoader()\n",
    "prices = loader.load_spot_prices()\n",
    "solar = loader.load_solar()\n",
    "\n",
    "df = prices.merge(solar, on='timestamp')\n",
    "\n",
    "# --- Predict shape structure ---\n",
    "estimator = ShapePredictor()\n",
    "shape_model = estimator.fit(df)\n",
    "\n",
    "# --- scale to weekly price ---\n",
    "hpfc = HPFCModel(shape_model)\n",
    "result = hpfc.forecast(df)\n",
    "\n",
    "# Weekly structural validation\n",
    "plots = HPFCPlots(result)\n",
    "plots.plot_hpfc_vs_observed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
